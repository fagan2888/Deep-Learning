{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from model import ConvolutionalAutoEncoder\n",
    "from cae_classifier import CAEClassifier\n",
    "from data import data_transforms, validation_data_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your device \n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the MNIST test set \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test set \n",
    "x_test, _ = list(test_loader)[0]\n",
    "batch_size = x_test.shape[0]\n",
    "x_test = x_test.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SparseAutoEncoder:\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([1024, 784]).\n\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([784, 256]) from checkpoint, the shape in current model is torch.Size([784, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6adb2c64d67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparseAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_SAE/test/sparse_test_30.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SparseAutoEncoder:\n\tsize mismatch for encoder.0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([1024, 784]).\n\tsize mismatch for encoder.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decoder.0.weight: copying a param with shape torch.Size([784, 256]) from checkpoint, the shape in current model is torch.Size([784, 1024])."
     ]
    }
   ],
   "source": [
    "# instantial the model and load the weights\n",
    "input_dim = 28*28*1\n",
    "model = SparseAutoEncoder(input_dim)\n",
    "model.load_state_dict(torch.load('test_SAE/test/sparse_test_30.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_imgs = model.encoder(x_test)\n",
    "decode_imgs = model.decoder(encode_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode imgs: torch.Size([128, 256])\n",
      "decode imgs: torch.Size([128, 784])\n"
     ]
    }
   ],
   "source": [
    "# print the shape of encode imgs and decode imgs\n",
    "print('encode imgs:', encode_imgs.size())\n",
    "print('decode imgs:', decode_imgs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decode_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d2de91c0af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# plot the decoded image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_yaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decode_imgs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the figure\n",
    "n = 10\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(n):\n",
    "    # plot the test image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].detach().numpy().reshape((28, 28)), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(True)\n",
    "    \n",
    "    # plot the decoded image\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decode_imgs[i].detach().numpy().reshape((28, 28)), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 96*96*3 # need to change\n",
    "fc1_input_features = 256\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseAutoEncoder(input_dim)\n",
    "model.load_state_dict(torch.load('test_SAE/classify/classify_train/sparse_ae_model_6.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data loader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder('../../data/ssl_data_96/supervised/train', transform=data_transforms),\n",
    "        batch_size=128, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ecfd10106689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_test, _ = list(data_loader)[0]\n",
    "batch_size = x_test.shape[0]\n",
    "x_test = x_test.view(128, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_imgs = model.encoder(x_test)\n",
    "decode_imgs = model.decoder(encode_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode imgs: torch.Size([128, 1024])\n",
      "decode imgs: torch.Size([128, 27648])\n"
     ]
    }
   ],
   "source": [
    "print('encode imgs:', encode_imgs.size())\n",
    "print('decode imgs:', decode_imgs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_model = SparseAutoEncoder(input_dim).to(device)\n",
    "sae_model.load_state_dict(torch.load('test_SAE/classify/classify_train/sparse_ae_model_6.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_model.encoder[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0717, 0.0606, 0.0991,  ..., 0.0682, 0.0435, 0.1017],\n",
       "        [0.0534, 0.0580, 0.0401,  ..., 0.0711, 0.0597, 0.0248],\n",
       "        [0.0183, 0.0299, 0.0459,  ..., 0.0555, 0.0165, 0.0277],\n",
       "        ...,\n",
       "        [0.1093, 0.1003, 0.1000,  ..., 0.0693, 0.0601, 0.0594],\n",
       "        [0.0208, 0.0568, 0.0403,  ..., 0.0174, 0.0197, 0.0556],\n",
       "        [0.0369, 0.0540, 0.0486,  ..., 0.0414, 0.0773, 0.0789]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(sae_model.encoder[0].weight.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_classifier = SAEClassifier(input_dim, fc1_input_features, n_classes).to(device)\n",
    "sae_classifier.initialize_from_sae(sae_model)\n",
    "sae_classifier.encoder[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 784])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_classifier.encoder[0].weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import data_transforms, validation_data_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoEncoder(nn.Module):\n",
    "    def __init__(self, fc_input_features):\n",
    "        super(ConvolutionalAutoEncoder, self).__init__()\n",
    "        self.fc_input_features = fc_input_features\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,16,5,1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16,32,5,1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32,64,4,1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=1, return_indices=True)\n",
    "        \n",
    "        # 17*17*64\n",
    "        self.fc1 = nn.Linear(self.fc_input_features, 8192)\n",
    "#         self.fc2 = nn.Linear(16384, 8192)\n",
    "#         self.fc3 = nn.Linear(8192, 16384)\n",
    "        self.fc2 = nn.Linear(8192, self.fc_input_features)\n",
    "\n",
    "\n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2, stride=1)\n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.unpool3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "        self.deconv1 = nn.ConvTranspose2d(64,32,4,1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32,16,5,1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(16,3,5,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x, poolIdx1 = self.maxpool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x, poolIdx2 = self.maxpool2(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x, poolIdx3 = self.maxpool3(x)\n",
    "        print('x shape', x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print('x shape', x.size())\n",
    "        encoded = self.relu(self.fc1(x))\n",
    "#         encoded = self.relu(self.fc2(x))\n",
    "#         x = self.relu(self.fc3(encoded))\n",
    "        x = self.relu(self.fc2(encoded))\n",
    "        print('x shape', x.size())\n",
    "        x = x.view(-1, 64, 17, 17)\n",
    "        x = self.unpool1(x, poolIdx3)\n",
    "        x = self.relu(self.bn2(self.deconv1(x)))\n",
    "        x = self.unpool2(x, poolIdx2)\n",
    "        x = self.relu(self.bn1(self.deconv2(x)))\n",
    "        x = self.unpool3(x, poolIdx1)\n",
    "        decoded = self.relu(self.deconv3(x))\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "randn = torch.randn(128, 3, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalAutoEncoder(17*17*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalAutoEncoder(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=18496, out_features=8192, bias=True)\n",
       "  (fc2): Linear(in_features=8192, out_features=18496, bias=True)\n",
       "  (unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(1, 1), padding=(0, 0))\n",
       "  (unpool2): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (unpool3): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (deconv2): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (deconv3): ConvTranspose2d(16, 3, kernel_size=(5, 5), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([128, 64, 17, 17])\n",
      "x shape torch.Size([128, 18496])\n",
      "x shape torch.Size([128, 18496])\n"
     ]
    }
   ],
   "source": [
    "x = model(randn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.BatchNorm2d(100)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = torch.load(args.pth, map_location=args.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
